from __future__ import print_function
import numpy as np
from sklearn import datasets, linear_model
import matplotlib.pyplot as plt
import pandas as pd
from sklearn.model_selection import train_test_split, KFold, cross_val_score
from sklearn import preprocessing
from sklearn.metrics import confusion_matrix
import seaborn as sns
from sklearn.utils import resample
from sklearn import model_selection
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import VotingClassifier
from sklearn.ensemble import BaggingClassifier
from sklearn.ensemble import AdaBoostClassifier, RandomForestClassifier, ExtraTreesClassifier
from sklearn.metrics import accuracy_score, f1_score, log_loss, precision_score, recall_score
   

# Define the sigmoid activator; we ask if we want the sigmoid or its derivative
def sigmoid_act(x, der=False):
    import numpy as np
    
    if (der==True) : #derivative of the sigmoid
        f = 1/(1+ np.exp(- x))*(1-1/(1+ np.exp(- x)))
    else : # sigmoid
        f = 1/(1+ np.exp(- x))
    
    return f

# We may employ the Rectifier Linear Unit (ReLU)
def ReLU_act(x, der=False):
    import numpy as np
    
    if (der == True): # the derivative of the ReLU is the Heaviside Theta
        f = np.heaviside(x, 1)
    else :
        f = np.maximum(x, 0)
    
    return f

data_set = pd.read_csv("C:\\Users\\Benafsha\\Downloads\\US_accidents20\\US_Accidents_June20.csv")
first_5=data_set.head()
weather_types=list(data_set.Weather_Condition.unique())

'''
for i in weather_types:
    print('variables.Weather_Condition[variables.Weather_Condition == ',i,']',"\n")
'''

print(data_set.columns)
variables=data_set[['Visibility(mi)','Weather_Condition','Wind_Speed(mph)','Precipitation(in)','Severity']]
 

print(variables)







variables.Weather_Condition[variables.Weather_Condition ==  'Light Rain' ] = 1

variables.Weather_Condition[variables.Weather_Condition ==  'Overcast' ] = 1

variables.Weather_Condition[variables.Weather_Condition ==  'Mostly Cloudy' ] = 1 

variables.Weather_Condition[variables.Weather_Condition ==  'Rain' ] = 2

variables.Weather_Condition[variables.Weather_Condition ==  'Light Snow' ] = 1

variables.Weather_Condition[variables.Weather_Condition ==  'Haze' ] = 2

variables.Weather_Condition[variables.Weather_Condition ==  'Scattered Clouds' ] = 1

variables.Weather_Condition[variables.Weather_Condition ==  'Partly Cloudy' ] = 1

variables.Weather_Condition[variables.Weather_Condition ==  'Clear' ] = 0

variables.Weather_Condition[variables.Weather_Condition ==  'Snow' ] = 3

variables.Weather_Condition[variables.Weather_Condition ==  'Light Freezing Drizzle' ] = 3

variables.Weather_Condition[variables.Weather_Condition ==  'Light Drizzle' ] = 2

variables.Weather_Condition[variables.Weather_Condition ==  'Fog' ] = 2

variables.Weather_Condition[variables.Weather_Condition ==  'Shallow Fog' ] = 2

variables.Weather_Condition[variables.Weather_Condition ==  'Heavy Rain' ] = 3

variables.Weather_Condition[variables.Weather_Condition ==  'Light Freezing Rain' ] = 2

variables.Weather_Condition[variables.Weather_Condition ==  'Cloudy' ] = 1

variables.Weather_Condition[variables.Weather_Condition ==  'Drizzle' ] = 2

variables.Weather_Condition[variables.Weather_Condition ==  'nan' ] = 1

variables.Weather_Condition[variables.Weather_Condition ==  'Light Rain Showers' ] = 2

variables.Weather_Condition[variables.Weather_Condition ==  'Mist' ] = 2

variables.Weather_Condition[variables.Weather_Condition ==  'Smoke' ] = 3

variables.Weather_Condition[variables.Weather_Condition ==  'Patches of Fog' ] = 2

variables.Weather_Condition[variables.Weather_Condition ==  'Light Freezing Fog' ] = 3

variables.Weather_Condition[variables.Weather_Condition ==  'Light Haze' ] = 2

variables.Weather_Condition[variables.Weather_Condition ==  'Light Thunderstorms and Rain' ] = 4

variables.Weather_Condition[variables.Weather_Condition ==  'Thunderstorms and Rain' ] = 5

variables.Weather_Condition[variables.Weather_Condition ==  'Fair' ] = 0

variables.Weather_Condition[variables.Weather_Condition ==  'Volcanic Ash' ] = 3

variables.Weather_Condition[variables.Weather_Condition ==  'Blowing Sand' ] = 3

variables.Weather_Condition[variables.Weather_Condition ==  'Blowing Dust / Windy' ] = 3

variables.Weather_Condition[variables.Weather_Condition ==  'Widespread Dust' ] = 3

variables.Weather_Condition[variables.Weather_Condition ==  'Fair / Windy' ] = 0

variables.Weather_Condition[variables.Weather_Condition ==  'Rain Showers' ] = 2

variables.Weather_Condition[variables.Weather_Condition ==  'Mostly Cloudy / Windy' ] = 0

variables.Weather_Condition[variables.Weather_Condition ==  'Light Rain / Windy' ] = 2

variables.Weather_Condition[variables.Weather_Condition ==  'Hail' ] = 4

variables.Weather_Condition[variables.Weather_Condition ==  'Heavy Drizzle' ] = 2

variables.Weather_Condition[variables.Weather_Condition ==  'Showers in the Vicinity' ] = 2

variables.Weather_Condition[variables.Weather_Condition ==  'Thunderstorm' ] = 5

variables.Weather_Condition[variables.Weather_Condition ==  'Light Rain Shower' ] = 2

variables.Weather_Condition[variables.Weather_Condition ==  'Light Rain with Thunder' ] = 3 

variables.Weather_Condition[variables.Weather_Condition ==  'Partly Cloudy / Windy' ] = 1

variables.Weather_Condition[variables.Weather_Condition ==  'Thunder in the Vicinity' ] = 3

variables.Weather_Condition[variables.Weather_Condition ==  'T-Storm' ] = 5

variables.Weather_Condition[variables.Weather_Condition ==  'Heavy Thunderstorms and Rain' ] = 6

variables.Weather_Condition[variables.Weather_Condition ==  'Thunder' ] = 5

variables.Weather_Condition[variables.Weather_Condition ==  'Heavy T-Storm' ] = 6 

variables.Weather_Condition[variables.Weather_Condition ==  'Funnel Cloud' ] = 0

variables.Weather_Condition[variables.Weather_Condition ==  'Heavy T-Storm / Windy' ] = 6

variables.Weather_Condition[variables.Weather_Condition ==  'Blowing Snow' ] = 6

variables.Weather_Condition[variables.Weather_Condition ==  'Light Thunderstorms and Snow' ] = 4

variables.Weather_Condition[variables.Weather_Condition ==  'Heavy Snow' ] = 6

variables.Weather_Condition[variables.Weather_Condition ==  'Low Drifting Snow' ] = 5

variables.Weather_Condition[variables.Weather_Condition ==  'Light Ice Pellets' ] = 3

variables.Weather_Condition[variables.Weather_Condition ==  'Ice Pellets' ] = 6

variables.Weather_Condition[variables.Weather_Condition ==  'Squalls' ] = 6

variables.Weather_Condition[variables.Weather_Condition ==  'N/A Precipitation' ] = 0

variables.Weather_Condition[variables.Weather_Condition ==  'Cloudy / Windy' ] = 2

variables.Weather_Condition[variables.Weather_Condition ==  'Light Fog' ] = 2

variables.Weather_Condition[variables.Weather_Condition ==  'Sand' ] = 3

variables.Weather_Condition[variables.Weather_Condition ==  'Snow Grains' ] = 3

variables.Weather_Condition[variables.Weather_Condition ==  'Snow Showers' ] = 4

variables.Weather_Condition[variables.Weather_Condition ==  'Heavy Thunderstorms and Snow' ] = 6

variables.Weather_Condition[variables.Weather_Condition ==  'Rain / Windy' ] = 4

variables.Weather_Condition[variables.Weather_Condition ==  'Heavy Rain / Windy' ] = 5

variables.Weather_Condition[variables.Weather_Condition ==  'Heavy Ice Pellets' ] = 6

variables.Weather_Condition[variables.Weather_Condition ==  'Light Snow / Windy' ] = 3

variables.Weather_Condition[variables.Weather_Condition ==  'Heavy Freezing Rain' ] = 6

variables.Weather_Condition[variables.Weather_Condition ==  'Small Hail' ] = 5

variables.Weather_Condition[variables.Weather_Condition ==  'Heavy Rain Showers' ] = 5

variables.Weather_Condition[variables.Weather_Condition ==  'T-Storm / Windy' ] = 5

variables.Weather_Condition[variables.Weather_Condition ==  'Patches of Fog / Windy' ] = 4

variables.Weather_Condition[variables.Weather_Condition ==  'Drizzle / Windy' ] = 1

variables.Weather_Condition[variables.Weather_Condition ==  'Thunder / Windy' ] = 5

variables.Weather_Condition[variables.Weather_Condition ==  'Wintry Mix' ] = 3

variables.Weather_Condition[variables.Weather_Condition ==  'Squalls / Windy' ] = 6 

variables.Weather_Condition[variables.Weather_Condition ==  'Rain Shower' ] = 2

variables.Weather_Condition[variables.Weather_Condition ==  'Drizzle and Fog' ] = 4 

variables.Weather_Condition[variables.Weather_Condition == 'Haze / Windy' ] =3

variables.Weather_Condition[variables.Weather_Condition ==  'Sand / Dust Whirlwinds' ] = 5

variables.Weather_Condition[variables.Weather_Condition ==  'Blowing Dust' ] = 5

variables.Weather_Condition[variables.Weather_Condition ==  'Fog / Windy' ] = 2

variables.Weather_Condition[variables.Weather_Condition ==  'Smoke / Windy' ] = 5

variables.Weather_Condition[variables.Weather_Condition ==  'Wintry Mix / Windy' ] = 4 

variables.Weather_Condition[variables.Weather_Condition ==  'Snow / Windy' ] = 4

variables.Weather_Condition[variables.Weather_Condition ==  'Light Rain Shower / Windy' ] = 3 

variables.Weather_Condition[variables.Weather_Condition ==  'Heavy Snow / Windy' ] = 5

variables.Weather_Condition[variables.Weather_Condition ==  'Snow and Sleet' ] = 5

variables.Weather_Condition[variables.Weather_Condition ==  'Light Freezing Rain / Windy' ] = 4

variables.Weather_Condition[variables.Weather_Condition ==  'Light Drizzle / Windy' ] = 3

variables.Weather_Condition[variables.Weather_Condition ==  'Light Snow and Sleet' ] = 4

variables.Weather_Condition[variables.Weather_Condition ==  'Partial Fog' ] = 2

variables.Weather_Condition[variables.Weather_Condition ==  'Light Snow Shower' ] = 3

variables.Weather_Condition[variables.Weather_Condition ==  'Light Snow and Sleet / Windy' ] = 4 

variables.Weather_Condition[variables.Weather_Condition ==  'Freezing Rain' ] = 4

variables.Weather_Condition[variables.Weather_Condition ==  'Blowing Snow / Windy' ] = 5 

variables.Weather_Condition[variables.Weather_Condition ==  'Freezing Drizzle' ] = 3

variables.Weather_Condition[variables.Weather_Condition ==  'Sleet' ] = 4

variables.Weather_Condition[variables.Weather_Condition ==  'Light Sleet' ] = 3 

variables.Weather_Condition[variables.Weather_Condition ==  'Rain and Sleet' ] = 5 

variables.Weather_Condition[variables.Weather_Condition ==  'Heavy Sleet' ] = 5

variables.Weather_Condition[variables.Weather_Condition ==  'Light Snow Grains' ] = 3

variables.Weather_Condition[variables.Weather_Condition ==  'Partial Fog / Windy' ] = 2

variables.Weather_Condition[variables.Weather_Condition ==  'Light Snow with Thunder' ] = 4

variables.Weather_Condition[variables.Weather_Condition ==  'Widespread Dust / Windy' ] = 4

variables.Weather_Condition[variables.Weather_Condition ==  'Sand / Dust Whirlwinds / Windy' ] = 6

variables.Weather_Condition[variables.Weather_Condition ==  'Tornado' ] = 7

variables.Weather_Condition[variables.Weather_Condition ==  'Snow and Thunder' ] = 6

variables.Weather_Condition[variables.Weather_Condition ==  'Snow and Sleet / Windy' ] = 5

variables.Weather_Condition[variables.Weather_Condition ==  'Heavy Snow with Thunder' ] = 5

variables.Weather_Condition[variables.Weather_Condition ==  'Thunder / Wintry Mix / Windy' ] = 6

variables.Weather_Condition[variables.Weather_Condition ==  'Light Snow Showers' ] = 3

variables.Weather_Condition[variables.Weather_Condition ==  'Heavy Blowing Snow' ] = 6

variables.Weather_Condition[variables.Weather_Condition ==  'Light Hail' ] = 3

variables.Weather_Condition[variables.Weather_Condition ==  'Heavy Smoke' ] = 5

variables.Weather_Condition[variables.Weather_Condition ==  'Heavy Thunderstorms with Small Hail' ] = 6  

variables.Weather_Condition[variables.Weather_Condition ==  'Light Thunderstorm' ] = 5

variables.Weather_Condition[variables.Weather_Condition ==  'Heavy Freezing Drizzle' ] = 5 

variables.Weather_Condition[variables.Weather_Condition ==  'Light Blowing Snow' ] = 4
 
variables.Weather_Condition[variables.Weather_Condition ==  'Thunderstorms and Snow' ] = 6

variables.Weather_Condition[variables.Weather_Condition ==  'Freezing Rain / Windy' ] = 5

variables.Weather_Condition[variables.Weather_Condition ==  'Dust Whirls' ] = 6

variables.Weather_Condition[variables.Weather_Condition ==  'Sand / Dust Whirls Nearby' ] = 6 

variables.Weather_Condition[variables.Weather_Condition ==  'Heavy Rain Shower' ] = 4

variables.Weather_Condition[variables.Weather_Condition ==  'Thunder and Hail' ] = 5

variables.Weather_Condition[variables.Weather_Condition ==  'Drifting Snow' ] = 5

variables.Weather_Condition[variables.Weather_Condition ==  'Thunder and Hail / Windy' ] = 5
variables.Weather_Condition[variables.Weather_Condition ==  'Drifting Snow' ] = 5

variables.Severity[variables.Severity ==  1 ] = 0
variables.Severity[variables.Severity ==  2 ] = 0
variables.Severity[variables.Severity ==  3 ] = 1
variables.Severity[variables.Severity ==  4 ] = 1



variables["Weather_Condition"] = variables["Weather_Condition"].fillna(0)
variables["Visibility(mi)"] = variables["Visibility(mi)"].fillna(10)
variables["Wind_Speed(mph)"] = variables["Wind_Speed(mph)"].fillna(5)
variables["Precipitation(in)"] = variables["Precipitation(in)"].fillna(0 )
#variables["Wind_Chill(F)"] = variables["Wind_Chill(F)"].fillna(32)
variables["Severity"] = variables["Severity"].fillna(1)

#variables.dropna(inplace=True)

xyx=variables['Weather_Condition'].value_counts(ascending=True)
print(variables['Weather_Condition'].value_counts(ascending=True))
print(variables['Severity'].value_counts(ascending=True))
print(variables['Visibility(mi)'].value_counts(ascending=True))
print(variables['Wind_Speed(mph)'].value_counts(ascending=True))
#print(variables['Wind_Chill(F)'].value_counts(ascending=True))
print(variables['Precipitation(in)'].value_counts(ascending=True))
print("unique weather con",variables.Weather_Condition.nunique())


df_majority = variables[variables.Severity==0]
df_minority = variables[variables.Severity==1]

df_minority_upsampled = resample(df_minority, 
                                 replace=True,    # sample without replacement
                                 n_samples=2402384,     # to match minority class
                                 random_state=123) # reproducible results
 
df_upsampled = pd.concat([df_majority, df_minority_upsampled])


 
# Display new class counts
df_upsampled.Severity.value_counts()
 
# Display new class counts
print(df_upsampled.Severity.value_counts())
X = df_upsampled.iloc[:, [0,1,2,3]].values
X = np.array(X)
X = preprocessing.scale(X)
Y = df_upsampled.iloc[:, [4]].values
labels= np.array(Y)
y_l = labels.reshape(4804768,1) #to convert labels to vector
#std_scale = preprocessing.StandardScaler().fit(X)
#X = std_scale.transform(X)


X_train, X_test, Y_train, Y_test = train_test_split(X, y_l,
    test_size=0.25, random_state=124)
print('Training records:',Y_train.size)
print('Test records:',Y_test.size)

class ANN:
    import numpy as np # linear algebra
    np.random.seed(100)
    
    '''
    Initialize the ANN;
    HiddenLayer vector : will contain the Layers' info
    w, b, phi = (empty) arrays that will contain all the w, b and activation functions for all the Layers
    mu = cost function
    eta = a standard learning rate initialization. It can be modified by the 'set_learning_rate' method
    '''
    def __init__(self) :
        self.HiddenLayer = []
        self.w = []
        self.b = []
        self.phi = []
        self.mu = []
        self.eta = 0.01 #set up the proper Learning Rate!!
    
    '''
    add method: to add layers to the network
    '''
    def add(self, lay = (4, 'ReLU') ):
        self.HiddenLayer.append(lay)
    
    '''
    FeedForward method: as explained before. 
    '''
    @staticmethod
    def FeedForward(w, b, phi, x):
        return phi(np.dot(w, x) + b)
        
    '''
    BackPropagation algorithm implementing the Gradient Descent 
    '''
    def BackPropagation(self, x, z, Y, w, b, phi):
        self.delta = []
        
        # We initialize ausiliar w and b that are used only inside the backpropagation algorithm once called        
        self.W = []
        self.B = []
        
        # We start computing the LAST error, the one for the OutPut Layer 
        self.delta.append(  (z[len(z)-1] - Y) * phi[len(z)-1](z[len(z)-1], der=True) )
        
        '''Now we BACKpropagate'''
        # We thus compute from next-to-last to first
        for i in range(0, len(z)-1):
            self.delta.append( np.dot( self.delta[i], w[len(z)- 1 - i] ) * phi[len(z)- 2 - i](z[len(z)- 2 - i], der=True) )
        
        # We have the error array ordered from last to first; we flip it to order it from first to last
        self.delta = np.flip(self.delta, 0)  
        
        # Now we define the delta as the error divided by the number of training samples
        self.delta = self.delta/self.X.shape[0] 
        
        '''GRADIENT DESCENT'''
        # We start from the first layer that is special, since it is connected to the Input Layer
        self.W.append( w[0] - self.eta * np.kron(self.delta[0], x).reshape( len(z[0]), x.shape[0] ) )
        self.B.append( b[0] - self.eta * self.delta[0] )
        
        # We now descend for all the other Hidden Layers + OutPut Layer
        for i in range(1, len(z)):
            self.W.append( w[i] - self.eta * np.kron(self.delta[i], z[i-1]).reshape(len(z[i]), len(z[i-1])) )
            self.B.append( b[i] - self.eta * self.delta[i] )
        
        # We return the descended parameters w, b
        return np.array(self.W), np.array(self.B)
    
    
    '''
    Fit method: it calls FeedForward and Backpropagation methods
    '''
    def Fit(self, X_train, Y_train):            
        print('Start fitting...')
        '''
        Input layer
        '''
        self.X = X_train
        self.Y = Y_train
        
        '''
        We now initialize the Network by retrieving the Hidden Layers and concatenating them 
        '''
        print('Model recap: \n')
        print('You are fitting an ANN with the following amount of layers: ', len(self.HiddenLayer))
        
        for i in range(0, len(self.HiddenLayer)) :
            print('Layer ', i+1)
            print('Number of neurons: ', self.HiddenLayer[i][0])
            if i==0:
                # We now try to use the He et al. Initialization from ArXiv:1502.01852
                self.w.append( np.random.randn(self.HiddenLayer[i][0] , self.X.shape[1])/np.sqrt(2/self.X.shape[1]) )
                self.b.append( np.random.randn(self.HiddenLayer[i][0])/np.sqrt(2/self.X.shape[1]))
                # Old initialization
                #self.w.append(2 * np.random.rand(self.HiddenLayer[i][0] , self.X.shape[1]) - 0.5)
                #self.b.append(np.random.rand(self.HiddenLayer[i][0]))
                
                # Initialize the Activation function
                for act in Activation_function.list_act():
                    if self.HiddenLayer[i][1] == act :
                        self.phi.append(Activation_function.get_act(act))
                        print('\tActivation: ', act)

            else :
                # We now try to use the He et al. Initialization from ArXiv:1502.01852
                self.w.append( np.random.randn(self.HiddenLayer[i][0] , self.HiddenLayer[i-1][0] )/np.sqrt(2/self.HiddenLayer[i-1][0]))
                self.b.append( np.random.randn(self.HiddenLayer[i][0])/np.sqrt(2/self.HiddenLayer[i-1][0]))
                # Old initialization
                #self.w.append(2*np.random.rand(self.HiddenLayer[i][0] , self.HiddenLayer[i-1][0] ) - 0.5)
                #self.b.append(np.random.rand(self.HiddenLayer[i][0]))
                
                # Initialize the Activation function
                for act in Activation_function.list_act():
                    if self.HiddenLayer[i][1] == act :
                        self.phi.append(Activation_function.get_act(act))
                        print('\tActivation: ', act)
            
        '''
        Now we start the Loop over the training dataset
        '''  
        for I in range(0, self.X.shape[0]): # loop over the training set
            '''
            Now we start the feed forward
            '''  
            self.z = []
            
            self.z.append( self.FeedForward(self.w[0], self.b[0], self.phi[0], self.X[I]) ) # First layers
            
            for i in range(1, len(self.HiddenLayer)): #Looping over layers
                self.z.append( self.FeedForward(self.w[i] , self.b[i], self.phi[i], self.z[i-1] ) )
        
            
            '''
            Here we backpropagate
            '''      
            self.w, self.b  = self.BackPropagation(self.X[I], self.z, self.Y[I], self.w, self.b, self.phi)
            
            '''
            Compute cost function
            ''' 
            self.mu.append(
                (1/2) * np.dot(self.z[len(self.z)-1] - self.Y[I], self.z[len(self.z)-1] - self.Y[I]) 
            )
            
        print('Fit done. \n')
        

    
    '''
    predict method
    '''
    def predict(self, X_test):
        
        print('Starting predictions...')
        
        self.pred = []
        self.XX = X_test
        
        for I in range(0, self.XX.shape[0]): # loop over the training set
            
            '''
            Now we start the feed forward
            '''  
            self.z = []
            
            self.z.append(self.FeedForward(self.w[0] , self.b[0], self.phi[0], self.XX[I])) #First layer
    
            for i in range(1, len(self.HiddenLayer)) : # loop over the layers
                self.z.append( self.FeedForward(self.w[i] , self.b[i], self.phi[i], self.z[i-1]))
       
            # Append the prediction;
            # We now need a binary classifier; we this apply an Heaviside Theta and we set to 0.5 the threshold
            # if y < 0.5 the output is zero, otherwise is zero
            self.pred.append( np.heaviside(  self.z[-1] - 0.5, 1)[0] ) # NB: self.z[-1]  is the last element of the self.z list
        
        print('Predictions done. \n')

        return np.array(self.pred)
   
    '''
    We need a method to retrieve the accuracy for each training data to follow the learning of the ANN
    '''
    def get_accuracy(self):
        return np.array(self.mu)
    # This is the averaged version
    def get_avg_accuracy(self):
        import math
        self.batch_loss = []
        for i in range(0, 10):
            self.loss_avg = 0
            # To set the batch in 10 element/batch we use math.ceil method
            # int(math.ceil((self.X.shape[0]-10) / 10.0))    - 1
            for m in range(0, (int(math.ceil((self.X.shape[0]-10) / 10.0))   )-1):
                #self.loss_avg += self.mu[60*i+m]/60
                self.loss_avg += self.mu[(int(math.ceil((self.X.shape[0]-10) / 10.0)) )*i + m]/(int(math.ceil((self.X.shape[0]-10) / 10.0)) )
            self.batch_loss.append(self.loss_avg)
        return np.array(self.batch_loss)
    
    '''
    Method to set the learning rate
    '''
    def set_learning_rate(self, et=0.01):
        self.eta = et
        
        
'''
layers class
'''
class layers :
    '''
    Layer method: used to call standar layers to add. 
    Easily generalizable to more general layers (Pooling and Convolutional layers)
    '''        
    def layer(p=4, activation = 'ReLU'):
        return (p, activation)

'''
Activation functions class
'''
class Activation_function(ANN):
    import numpy as np
    
    def __init__(self) :
        super().__init__()
        
    '''
    Define the sigmoid activator; we ask if we want the sigmoid or its derivative
    '''
    def sigmoid_act(x, der=True):
        if (der==True) : #derivative of the sigmoid
            f = 1/(1+ np.exp(- x))*(1-1/(1+ np.exp(- x)))
        else : # sigmoid
            f = 1/(1+ np.exp(- x))
        return f

    '''
    Define the Rectifier Linear Unit (ReLU)
    '''
    def ReLU_act(x, der=True):
        if (der == True): # the derivative of the ReLU is the Heaviside Theta
            f = np.heaviside(x, 1)
        else :
            f = np.maximum(x, 0)
        return f
    
    def list_act():
        return ['sigmoid', 'ReLU']
    
    def get_act(string = 'ReLU'):
        if string == 'ReLU':
            return ReLU_act
        elif string == 'sigmoid':
            return sigmoid_act
        else :
            return sigmoid_act
        
model_ann = ANN()
#model_ann.add(layers.layer(8, 'ReLU'))
model_ann.add(layers.layer(7, 'ReLU'))
#model_ann.add(layers.layer(1, 'sigmoid'))
model_ann.add(layers.layer(3, 'ReLU'))
#model_ann.add(layers.layer(1, 'sigmoid'))
#model_ann.add(layers.layer(2, 'ReLU'))
model_ann.add(layers.layer(1, 'sigmoid'))

model_ann.set_learning_rate(0.001)

ann_clff=model_ann.Fit(X_train, Y_train)
acc_val = model_ann.get_accuracy()
acc_avg_val = model_ann.get_avg_accuracy()

predictions = model_ann.predict(X_test)

plt.figure(figsize=(10,6))
plt.scatter(np.arange(1, X_train.shape[0]+1), acc_val, alpha=0.3, s=4, label='mu')
plt.title('Loss for each training data point', fontsize=20)
plt.xlabel('Training data', fontsize=16)
plt.ylabel('Loss', fontsize=16)
plt.show()

plt.figure(figsize=(10,6))
plt.scatter(np.arange(1, len(acc_avg_val)+1), acc_avg_val, label='mu')
plt.title('Averege Loss by epoch', fontsize=20)
plt.xlabel('Training data', fontsize=16)
plt.ylabel('Loss', fontsize=16)
plt.show()
# Plot the confusion matrix
cm = confusion_matrix(Y_test, predictions)
accuracy_model= (cm[0,0] + cm[1,1]) / Y_test.size
print("accuracy_ann=",accuracy_model)

#from sklearn.tree import DecisionTreeClassifier 
dtree_model = DecisionTreeClassifier(max_depth = 2).fit(X_train, Y_train) 
dtree_predictions = dtree_model.predict(X_test) 
accuracy_dt = dtree_model.score(X_test, Y_test)
# creating a confusion matrix 
cm_dt = confusion_matrix(Y_test, dtree_predictions) 

# training a Naive Bayes classifier 
from sklearn.naive_bayes import GaussianNB 
gnb = GaussianNB().fit(X_train, Y_train) 

gnb_predictions = gnb.predict(X_test) 
  
# accuracy on X_test 
accuracy = gnb.score(X_test, Y_test) 
print(accuracy)
  
# creating a confusion matrix 
cm = confusion_matrix(Y_test, gnb_predictions) 




ann_clf = ann_clff
DTree_clf = dtree_model
gnb_clf=gnb
#SVC_clf = SVC()

#Voting classification
voting_clf = VotingClassifier(estimators=[('ann', ann_clf), ('dtree', DTree_clf)], voting='hard')
voting_clf.fit(X_train, Y_train)
preds = voting_clf.predict(X_test)
acc = accuracy_score(Y_test, preds)
l_loss = log_loss(Y_test, preds)
f1 = f1_score(Y_test, preds)
cm_ve=confusion_matrix(Y_test, preds)
print("Accuracy for voting ensemble is: " + str(acc))
print("Log Loss is: " + str(l_loss))
print("F1 Score is: " + str(f1))
print("cm for voting ensemble" )
print(cm_ve)

print("accuracy for dtree is" + str(accuracy_dt))
print("cm for dtree")
print(cm_dt)

print("accuracy for gnb is" + str(accuracy))
print("cm for gnb")
print(cm)

'''
#bagging classification
logreg_bagging_model = BaggingClassifier(base_estimator=ann_clf, n_estimators=50, random_state=12)
dtree_bagging_model = BaggingClassifier(base_estimator=DTree_clf, n_estimators=50, random_state=12)
random_forest = RandomForestClassifier(n_estimators=100, random_state=12)
extra_trees = ExtraTreesClassifier(n_estimators=100, random_state=12)

def bagging_ensemble(model):
    k_folds = KFold(n_splits=20, random_state=12)
    results = cross_val_score(model, X_train, Y_train, cv=k_folds)
    print(results.mean())

bagging_ensemble(logreg_bagging_model)
bagging_ensemble(dtree_bagging_model)
bagging_ensemble(random_forest)
bagging_ensemble(extra_trees)
'''

'''
#boosting classification
k_folds = KFold(n_splits=20, random_state=12)

num_estimators = [20, 40, 60, 80, 100]

for i in num_estimators:
    ada_boost = AdaBoostClassifier(n_estimators=i, random_state=12)
    results = cross_val_score(ada_boost, X_train, Y_train, cv=k_folds)
    print("Results for {} estimators:".format(i))
    print(results.mean())
'''

'''
dict_severity = { 
    0 : 'Less_severe',
    1 : 'More_severe'
}

df_cm = pd.DataFrame(cm, index = [dict_severity[i] for i in range(0,2)], columns = [dict_severity[i] for i in range(0,2)])
plt.figure(figsize = (7,7))
sns.heatmap(df_cm, annot=True, cmap=plt.cm.Blues, fmt='g')
plt.xlabel("Predicted Class", fontsize=18)
plt.ylabel("True Class", fontsize=18)
plt.show()
'''

